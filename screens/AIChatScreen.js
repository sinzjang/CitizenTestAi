import React, { useState, useEffect, useRef, useCallback } from 'react';
import {
  View,
  Text,
  TextInput,
  TouchableOpacity,
  ScrollView,
  Alert,
  StyleSheet,
  ActivityIndicator,
  KeyboardAvoidingView,
  Platform,
  Modal,
  StatusBar,
} from 'react-native';
import { SafeAreaView } from 'react-native-safe-area-context';
import { useFocusEffect } from '@react-navigation/native';
import { Ionicons } from '@expo/vector-icons';
import * as Speech from 'expo-speech';
import { t } from '../utils/i18n';
// import * as SpeechRecognition from 'expo-speech-recognition';

const AIChatScreen = ({ navigation }) => {
  const [isConnecting, setIsConnecting] = useState(false);
  const [isConnected, setIsConnected] = useState(false);
  const [connectionStatus, setConnectionStatus] = useState('');
  const [messages, setMessages] = useState([]);
  const [inputText, setInputText] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [ttsEnabled, setTtsEnabled] = useState(true);
  const [conversationHistory, setConversationHistory] = useState([]);
  const [chatStarted, setChatStarted] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [sttEnabled, setSttEnabled] = useState(true);
  const [recognitionPermission, setRecognitionPermission] = useState(null);
  const [aiMode, setAiMode] = useState(true); // true: GPT ì˜¨ë¼ì¸ ëª¨ë“œ, false: ë¡œì»¬ í™˜ê²½ ëª¨ë“œ
  const [selectedVoice, setSelectedVoice] = useState('alloy'); // OpenAI ìŒì„± ì„ íƒ
  const [showVoiceSelector, setShowVoiceSelector] = useState(false);
  
  const scrollViewRef = useRef();

  // OpenAI TTS ìŒì„± ì˜µì…˜ (ì‹¤ì œ ì‚¬ëŒ ì´ë¦„ìœ¼ë¡œ ë³€ê²½)
  const openaiVoices = [
    { id: 'alloy', name: 'Michael', descriptionKey: 'michael' },
    { id: 'echo', name: 'David', descriptionKey: 'david' },
    { id: 'fable', name: 'James', descriptionKey: 'james' },
    { id: 'nova', name: 'Sarah', descriptionKey: 'sarah' },
    { id: 'onyx', name: 'Robert', descriptionKey: 'robert' },
    { id: 'shimmer', name: 'Emma', descriptionKey: 'emma' }
  ];



  // ChatGPT API ì„¤ì •
  const OPENAI_API_KEY = process.env.EXPO_PUBLIC_OPENAI_API_KEY || 'your-api-key-here';
  const OPENAI_API_URL = 'https://api.openai.com/v1/chat/completions';





  // AI ëª¨ë“œ ë³€ê²½ ì•Œë¦¼ í•¨ìˆ˜
  const announceAiModeChange = async (newAiMode) => {
    if (!ttsEnabled) return;
    
    try {
      const message = newAiMode ? 'AI Interview' : 'Regular Interview';
      await Speech.speak(message, {
        language: 'en-US',
        rate: 0.75,
        onStart: () => console.log(`ğŸ”Š AI mode changed to: ${message}`),
        onDone: () => console.log('ğŸ”Š AI mode announcement completed'),
        onError: (error) => console.error('ğŸ”Š AI mode announcement error:', error)
      });
    } catch (error) {
      console.error('ğŸ”Š AI mode announcement failed:', error);
    }
  };

  // í˜„ì¬ ì¬ìƒ ì¤‘ì¸ ìƒ˜í”Œ ì¤‘ì§€ í•¨ìˆ˜
  const stopCurrentSample = async () => {
    try {
      // ëª¨ë°”ì¼ í™˜ê²½: Expo AV Sound ì¤‘ì§€
      if (typeof window !== 'undefined' && window.currentSampleSound) {
        console.log('ğŸ”Š Stopping current sample sound (mobile)');
        try {
          if (window.currentSampleSound && typeof window.currentSampleSound.stopAsync === 'function') {
            await window.currentSampleSound.stopAsync();
          }
          if (window.currentSampleSound && typeof window.currentSampleSound.unloadAsync === 'function') {
            await window.currentSampleSound.unloadAsync();
          }
        } catch (soundError) {
          console.log('ğŸ”Š Sample sound cleanup error:', soundError);
        } finally {
          window.currentSampleSound = null;
        }
      }
      
      // ì›¹ í™˜ê²½: HTML Audio ì¤‘ì§€
      if (typeof window !== 'undefined' && window.currentSampleAudio) {
        console.log('ğŸ”Š Stopping current sample audio (web)');
        try {
          if (window.currentSampleAudio && typeof window.currentSampleAudio.pause === 'function') {
            window.currentSampleAudio.pause();
            window.currentSampleAudio.currentTime = 0;
          }
        } catch (audioError) {
          console.log('ğŸ”Š Sample audio cleanup error:', audioError);
        } finally {
          window.currentSampleAudio = null;
        }
      }
      
      // Expo Speech ì¤‘ì§€ (í´ë°±ìš©)
      try {
        await Speech.stop();
      } catch (speechError) {
        console.log('ğŸ”Š Speech stop error:', speechError);
      }
    } catch (error) {
      console.error('ğŸ”Š Error stopping current sample:', error);
    }
  };

  // ìŒì„± ìƒ˜í”Œ ì¬ìƒ í•¨ìˆ˜ (speakTextWithOpenAIì™€ ë™ì¼í•œ ë°©ì‹ ì‚¬ìš©)
  const playVoiceSample = async (voiceId) => {
    if (!ttsEnabled) {
      Alert.alert('TTS ë¹„í™œì„±í™”', 'TTSë¥¼ í™œì„±í™”í•´ì•¼ ìŒì„± ìƒ˜í”Œì„ ë“¤ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.');
      return;
    }

    try {
      console.log(`ğŸ”Š Playing voice sample for: ${voiceId}`);
      
      // ì§„í–‰ ì¤‘ì¸ ìŒì„± ì¤‘ì§€
      await stopCurrentSample();
      
      const sampleText = "Hello, I'm your interview assistant. How are you today?";
      
      // AI ëª¨ë“œì¼ ë•Œ OpenAI TTS ì‚¬ìš©
      if (aiMode && typeof fetch !== 'undefined') {
        console.log('ğŸ”Š Attempting OpenAI TTS for voice sample with voice:', voiceId);
        
        try {
          const response = await fetch('https://api.openai.com/v1/audio/speech', {
            method: 'POST',
            headers: {
              'Authorization': `Bearer ${OPENAI_API_KEY}`,
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              model: 'tts-1-hd',
              input: sampleText,
              voice: voiceId,
              response_format: 'mp3',
              speed: 1.0
            }),
          });

          if (!response.ok) {
            throw new Error(`TTS API error! status: ${response.status}`);
          }

          const audioBlob = await response.blob();
          
          // React Nativeì—ì„œ Blobì„ base64ë¡œ ë³€í™˜í•˜ì—¬ ì¬ìƒ
          if (Platform.OS === 'ios' || Platform.OS === 'android') {
            console.log('ğŸ”Š Converting OpenAI audio for mobile sample playback');
            
            // FileReaderë¥¼ ì‚¬ìš©í•˜ì—¬ Blobì„ base64ë¡œ ë³€í™˜
            const reader = new FileReader();
            reader.onload = async () => {
              try {
                const base64Audio = reader.result.split(',')[1]; // data:audio/mp3;base64, ì œê±°
                
                // Expo AVë¥¼ ì‚¬ìš©í•˜ì—¬ base64 ì˜¤ë””ì˜¤ ì¬ìƒ
                const { Audio } = require('expo-av');
                await Audio.setAudioModeAsync({
                  allowsRecordingIOS: false,
                  staysActiveInBackground: false,
                  playsInSilentModeIOS: true,
                  shouldDuckAndroid: true,
                  playThroughEarpieceAndroid: false,
                });
                
                const { sound } = await Audio.Sound.createAsync(
                  { uri: `data:audio/mp3;base64,${base64Audio}` },
                  { shouldPlay: true }
                );
                
                // ì „ì—­ ë³€ìˆ˜ì— ì €ì¥í•˜ì—¬ ì¤‘ì§€í•  ìˆ˜ ìˆë„ë¡ í•¨
                if (typeof window !== 'undefined') {
                  window.currentSampleSound = sound;
                }
                
                sound.setOnPlaybackStatusUpdate((status) => {
                  if (status.didJustFinish) {
                    console.log('ğŸ”Š âœ… Voice sample playback completed on mobile');
                    sound.unloadAsync();
                    if (typeof window !== 'undefined') {
                      window.currentSampleSound = null;
                    }
                  }
                });
                
                console.log('ğŸ”Š âœ… Voice sample started on mobile with voice:', voiceId);
              } catch (error) {
                console.error('ğŸ”Š âŒ Mobile sample playback error:', error);
                throw error; // í´ë°±ìœ¼ë¡œ ì´ë™
              }
            };
            
            reader.readAsDataURL(audioBlob);
            return; // ì„±ê³µì ìœ¼ë¡œ OpenAI TTS ì‚¬ìš©
          } else {
            // ì›¹ í™˜ê²½ì—ì„œëŠ” ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            const audioUrl = URL.createObjectURL(audioBlob);
            const audio = new Audio(audioUrl);
            
            // ì „ì—­ ë³€ìˆ˜ì— ì €ì¥í•˜ì—¬ ì¤‘ì§€í•  ìˆ˜ ìˆë„ë¡ í•¨
            window.currentSampleAudio = audio;
            
            audio.onended = () => {
              URL.revokeObjectURL(audioUrl);
              window.currentSampleAudio = null;
              console.log('ğŸ”Š Voice sample playback completed on web');
            };
            audio.onerror = () => {
              URL.revokeObjectURL(audioUrl);
              window.currentSampleAudio = null;
            };
            
            await audio.play();
            console.log('ğŸ”Š âœ… Voice sample started on web with voice:', voiceId);
            return; // ì„±ê³µì ìœ¼ë¡œ OpenAI TTS ì‚¬ìš©
          }
        } catch (error) {
          console.error('ğŸ”Š âŒ OpenAI TTS sample failed, falling back to Expo Speech:', error);
          // í´ë°±ìœ¼ë¡œ ê³„ì† ì§„í–‰
        }
      }
      
      // í´ë°±: Expo Speech ì‚¬ìš© (ë¡œì»¬ ëª¨ë“œì´ê±°ë‚˜ OpenAI TTS ì‹¤íŒ¨ ì‹œ)
      console.log('ğŸ”Š Using Expo Speech fallback for voice sample');
      await Speech.speak(sampleText, {
        language: 'en-US',
        rate: 0.75,
        onStart: () => console.log('ğŸ”Š Voice sample started with Expo Speech'),
        onDone: () => console.log('ğŸ”Š Voice sample completed with Expo Speech'),
        onError: (error) => console.error('ğŸ”Š Voice sample error:', error)
      });
      
    } catch (error) {
      console.error('ğŸ”Š Voice sample playback failed:', error);
      Alert.alert('ìŒì„± ìƒ˜í”Œ ì˜¤ë¥˜', 'ìŒì„± ìƒ˜í”Œì„ ì¬ìƒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
    }
  };

  // AI ëª¨ë“œì— ë”°ë¥¸ TTS í•¨ìˆ˜
  const speakTextWithOpenAI = async (text) => {
    console.log('ğŸ”Š speakTextWithOpenAI called');
    console.log('ğŸ”Š TTS Enabled:', ttsEnabled);
    console.log('ğŸ”Š AI Mode:', aiMode);
    console.log('ğŸ”Š Platform:', Platform.OS);
    console.log('ğŸ”Š Text to speak:', text);
    
    if (!ttsEnabled) {
      console.log('ğŸ”Š TTS is disabled, skipping speech');
      return;
    }
    
    try {
      console.log('ğŸ”Š Setting isSpeaking to true');
      setIsSpeaking(true);
      
      // GPT ëª¨ë“œì¼ ë•ŒëŠ” ëª¨ë“  í”Œë«í¼ì—ì„œ OpenAI TTS ì‹œë„
      if (aiMode && typeof fetch !== 'undefined') {
        console.log('ğŸ”Š Attempting OpenAI TTS API for mobile with voice:', selectedVoice);
        
        try {
          const response = await fetch('https://api.openai.com/v1/audio/speech', {
            method: 'POST',
            headers: {
              'Authorization': `Bearer ${OPENAI_API_KEY}`,
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              model: 'tts-1-hd',
              input: text,
              voice: selectedVoice,
              response_format: 'mp3',
              speed: 1.0
            }),
          });

          if (!response.ok) {
            throw new Error(`TTS API error! status: ${response.status}`);
          }

          const audioBlob = await response.blob();
          
          // React Nativeì—ì„œ Blobì„ base64ë¡œ ë³€í™˜í•˜ì—¬ ì¬ìƒ
          if (Platform.OS === 'ios' || Platform.OS === 'android') {
            console.log('ğŸ”Š Converting OpenAI audio for mobile playback');
            
            // FileReaderë¥¼ ì‚¬ìš©í•˜ì—¬ Blobì„ base64ë¡œ ë³€í™˜
            const reader = new FileReader();
            reader.onload = async () => {
              try {
                const base64Audio = reader.result.split(',')[1]; // data:audio/mp3;base64, ì œê±°
                
                // Expo AVë¥¼ ì‚¬ìš©í•˜ì—¬ base64 ì˜¤ë””ì˜¤ ì¬ìƒ
                const { Audio } = require('expo-av');
                await Audio.setAudioModeAsync({
                  allowsRecordingIOS: false,
                  staysActiveInBackground: false,
                  playsInSilentModeIOS: true,
                  shouldDuckAndroid: true,
                  playThroughEarpieceAndroid: false,
                });
                
                const { sound } = await Audio.Sound.createAsync(
                  { uri: `data:audio/mp3;base64,${base64Audio}` },
                  { shouldPlay: true }
                );
                
                // ì „ì—­ ë³€ìˆ˜ì— ì €ì¥í•˜ì—¬ cleanupì—ì„œ ì¤‘ì§€í•  ìˆ˜ ìˆë„ë¡ í•¨
                if (typeof window !== 'undefined') {
                  window.currentExpoSound = sound;
                }
                
                sound.setOnPlaybackStatusUpdate((status) => {
                  if (status.didJustFinish) {
                    console.log('ğŸ”Š âœ… OpenAI TTS playback completed on mobile');
                    setIsSpeaking(false);
                    sound.unloadAsync();
                    if (typeof window !== 'undefined') {
                      window.currentExpoSound = null;
                    }
                  }
                });
                
                console.log('ğŸ”Š âœ… OpenAI TTS started on mobile with voice:', selectedVoice);
              } catch (error) {
                console.error('ğŸ”Š âŒ Mobile audio playback error:', error);
                throw error; // í´ë°±ìœ¼ë¡œ ì´ë™
              }
            };
            
            reader.readAsDataURL(audioBlob);
            return; // ì„±ê³µì ìœ¼ë¡œ OpenAI TTS ì‚¬ìš©
          } else {
            // ì›¹ í™˜ê²½ì—ì„œëŠ” ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            const audioUrl = URL.createObjectURL(audioBlob);
            const audio = new Audio(audioUrl);
            window.currentAudio = audio;
            
            audio.onended = () => {
              setIsSpeaking(false);
              URL.revokeObjectURL(audioUrl);
              window.currentAudio = null;
            };
            audio.onerror = () => {
              setIsSpeaking(false);
              URL.revokeObjectURL(audioUrl);
              window.currentAudio = null;
            };
            
            await audio.play();
            console.log('ğŸ”Š âœ… OpenAI TTS started on web with voice:', selectedVoice);
            return; // ì„±ê³µì ìœ¼ë¡œ OpenAI TTS ì‚¬ìš©
          }
        } catch (error) {
          console.error('ğŸ”Š âŒ OpenAI TTS failed, falling back to Expo Speech:', error);
          // í´ë°±ìœ¼ë¡œ ê³„ì† ì§„í–‰
        }
      }
      
      // í´ë°±: Expo Speech ì‚¬ìš© (ë¡œì»¬ ëª¨ë“œì´ê±°ë‚˜ OpenAI TTS ì‹¤íŒ¨ ì‹œ)
      if (Platform.OS === 'ios' || Platform.OS === 'android') {
        console.log('ğŸ”Š Using Expo Speech fallback for React Native environment');
        console.log('ğŸ”Š Text to speak:', text);
        
        try {
          console.log('ğŸ”Š Stopping any current speech...');
          // ë¨¼ì € í˜„ì¬ ì¬ìƒ ì¤‘ì¸ ìŒì„± ì¤‘ì§€
          await Speech.stop();
          
          console.log('ğŸ”Š Getting available voices...');
          // ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
          const voices = await Speech.getAvailableVoicesAsync();
          let selectedVoice = undefined;
          
          console.log('ğŸ”Š Total voices available:', voices.length);
          
          // ì˜ì–´ ìŒì„± ì¤‘ì—ì„œ AI ëª¨ë“œì— ë”°ë¼ ë‹¤ë¥¸ ìŒì„± ì„ íƒ
          const englishVoices = voices.filter(voice => 
            voice.language.includes('en-US') || voice.language.includes('en_US')
          );
          
          console.log('ğŸ”Š English voices found:', englishVoices.length);
          
          if (englishVoices.length > 0) {
            if (aiMode) {
              // GPT ì˜¨ë¼ì¸ ëª¨ë“œ: ê³ ê¸‰ ì—¬ì„± ìŒì„± (ìì—°ìŠ¤ëŸ½ê³  ì „ë¬¸ì )
              selectedVoice = englishVoices.find(voice => 
                voice.name.toLowerCase().includes('samantha') ||
                voice.name.toLowerCase().includes('karen') ||
                voice.name.toLowerCase().includes('female') || 
                voice.name.toLowerCase().includes('woman') ||
                voice.quality === 'Enhanced'
              ) || englishVoices[0];
              console.log('ğŸ”Š GPT Mode - Selected premium voice:', selectedVoice.name);
            } else {
              // ë¡œì»¬ í™˜ê²½ ëª¨ë“œ: ê¸°ë³¸ ë‚¨ì„± ìŒì„± (ë‹¨ìˆœí•˜ê³  ë¡œë´‡í‹±)
              selectedVoice = englishVoices.find(voice => 
                voice.name.toLowerCase().includes('male') ||
                voice.name.toLowerCase().includes('man') ||
                voice.name.toLowerCase().includes('alex') ||
                voice.name.toLowerCase().includes('daniel') ||
                voice.quality === 'Default'
              ) || englishVoices[englishVoices.length - 1]; // ë§ˆì§€ë§‰ ìŒì„± (ë³´í†µ ê¸°ë³¸ ìŒì„±)
              console.log('ğŸ”Š Local Mode - Selected basic voice:', selectedVoice.name);
            }
          }
          
          console.log('ğŸ”Š Starting Speech.speak...');
          
          // AI ëª¨ë“œì— ë”°ë¥¸ ë‹¤ë¥¸ ìŒì„± ì„¤ì •
          const speechOptions = aiMode ? {
            // GPT ì˜¨ë¼ì¸ ëª¨ë“œ: ìì—°ìŠ¤ëŸ½ê³  í‘œí˜„ë ¥ ìˆëŠ” ì„¤ì •
            language: 'en-US',
            pitch: 1.1, // ì•½ê°„ ë†’ì€ ìŒì¡° (ì¹œê·¼í•¨)
            rate: 0.8, // ì ë‹¹í•œ ì†ë„ (ì´í•´í•˜ê¸° ì‰½ê²Œ)
            quality: Speech.VoiceQuality.Enhanced,
            voice: selectedVoice?.identifier
          } : {
            // ë¡œì»¬ í™˜ê²½ ëª¨ë“œ: ë‹¨ì¡°ë¡­ê³  ê¸°ê³„ì ì¸ ì„¤ì •
            language: 'en-US',
            pitch: 0.9, // ë‚®ì€ ìŒì¡° (ë¡œë´‡í‹±)
            rate: 0.6, // ëŠë¦° ì†ë„ (ê¸°ê³„ì )
            quality: Speech.VoiceQuality.Default,
            voice: selectedVoice?.identifier
          };
          
          console.log('ğŸ”Š Speech options:', speechOptions);
          
          // ì½œë°± í•¨ìˆ˜ ì¶”ê°€
          speechOptions.onStart = () => {
            console.log('ğŸ”Š âœ… Speech STARTED with voice:', selectedVoice?.name || 'default');
            setIsSpeaking(true);
          };
          speechOptions.onDone = () => {
            console.log('ğŸ”Š âœ… Speech COMPLETED');
            setIsSpeaking(false);
          };
          speechOptions.onStopped = () => {
            console.log('ğŸ”Š â¹ï¸ Speech STOPPED');
            setIsSpeaking(false);
          };
          speechOptions.onError = (error) => {
            console.error('ğŸ”Š âŒ Speech ERROR:', error);
            setIsSpeaking(false);
          };
          
          await Speech.speak(text, speechOptions);
          console.log('ğŸ”Š Speech.speak call completed');
        } catch (error) {
          console.error('ğŸ”Š âŒ Expo Speech error:', error);
          setIsSpeaking(false);
        }
        return;
      }
    } catch (error) {
      console.error('OpenAI TTS Error:', error);
      setIsSpeaking(false);
      // Fallback to expo-speech
      try {
        console.log('Falling back to Expo Speech');
        await Speech.speak(text, {
          language: 'en-US',
          pitch: 1.0,
          rate: 0.8,
          onDone: () => setIsSpeaking(false),
          onError: () => setIsSpeaking(false)
        });
      } catch (fallbackError) {
        console.error('Fallback TTS Error:', fallbackError);
        setIsSpeaking(false);
      }
    }
  };

  const stopSpeaking = async () => {
    try {
      console.log('Stopping speech...');
      
      // Stop both OpenAI TTS and expo-speech
      if (typeof window !== 'undefined' && window.currentAudio) {
        window.currentAudio.pause();
        window.currentAudio = null;
      }
      
      // Expo Speech ì¤‘ì§€
      await Speech.stop();
      setIsSpeaking(false);
      console.log('Speech stopped successfully');
    } catch (error) {
      console.error('Error stopping speech:', error);
      setIsSpeaking(false);
    }
  };



  // ë¡œì»¬ AI ì‘ë‹µ í•¨ìˆ˜ (ì˜¤í”„ë¼ì¸ ëª¨ë“œ)
  const getLocalAIResponse = async (userMessage) => {
    // ì‹œë¯¼ê¶Œ ê´€ë ¨ í‚¤ì›Œë“œ ê¸°ë°˜ ì‘ë‹µ
    const message = userMessage.toLowerCase();
    
    if (message.includes('constitution') || message.includes('í—Œë²•')) {
      return "í—Œë²•(Constitution)ì€ ë¯¸êµ­ì˜ ìµœê³ ë²•ì…ë‹ˆë‹¤. 1787ë…„ì— ì œì •ë˜ì—ˆìœ¼ë©°, ì •ë¶€ì˜ êµ¬ì¡°ì™€ êµ­ë¯¼ì˜ ê¶Œë¦¬ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.";
    }
    
    if (message.includes('president') || message.includes('ëŒ€í†µë ¹')) {
      return "í˜„ì¬ ë¯¸êµ­ ëŒ€í†µë ¹ì€ ì¡° ë°”ì´ë“ (Joe Biden)ì…ë‹ˆë‹¤. ëŒ€í†µë ¹ì€ í–‰ì •ë¶€ì˜ ìˆ˜ì¥ì´ë©° 4ë…„ ì„ê¸°ë¡œ ì„ ì¶œë©ë‹ˆë‹¤.";
    }
    
    if (message.includes('bill of rights') || message.includes('ê¶Œë¦¬ì¥ì „')) {
      return "ê¶Œë¦¬ì¥ì „(Bill of Rights)ì€ í—Œë²•ì˜ ì²« 10ê°œ ìˆ˜ì •ì¡°í•­ì…ë‹ˆë‹¤. ì–¸ë¡ ì˜ ììœ , ì¢…êµì˜ ììœ  ë“± ê¸°ë³¸ê¶Œì„ ë³´ì¥í•©ë‹ˆë‹¤.";
    }
    
    if (message.includes('independence') || message.includes('ë…ë¦½')) {
      return "ë¯¸êµ­ì€ 1776ë…„ 7ì›” 4ì¼ì— ë…ë¦½ì„ ì–¸ì„œë¥¼ ì±„íƒí•˜ì—¬ ì˜êµ­ìœ¼ë¡œë¶€í„° ë…ë¦½í–ˆìŠµë‹ˆë‹¤.";
    }
    
    if (message.includes('hello') || message.includes('ì•ˆë…•') || message.includes('hi')) {
      return "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ë¡œì»¬ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë¯¸êµ­ ì‹œë¯¼ê¶Œ ë©´ì ‘ ì¤€ë¹„ë¥¼ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í—Œë²•, ì—­ì‚¬, ì •ë¶€ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”!";
    }
    
    // ê¸°ë³¸ ì‘ë‹µ
    return "ì£„ì†¡í•©ë‹ˆë‹¤. ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” ì œí•œëœ ì •ë³´ë§Œ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë” ìì„¸í•œ ë‹µë³€ì„ ì›í•˜ì‹œë©´ ìƒë‹¨ì˜ AI í† ê¸€ì„ ì¼œì„œ GPT ì˜¨ë¼ì¸ ëª¨ë“œë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.";
  };

  // ChatGPT API í˜¸ì¶œ í•¨ìˆ˜
  const callChatGPT = async (messages) => {
    try {
      const response = await fetch(OPENAI_API_URL, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${OPENAI_API_KEY}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'gpt-3.5-turbo',
          messages: messages,
          max_tokens: 300,
          temperature: 0.7,
        }),
      });

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      const data = await response.json();
      return data.choices[0].message.content;
    } catch (error) {
      console.error('ChatGPT API Error:', error);
      throw error;
    }
  };

  useEffect(() => {
    testChatGPTConnection();
    checkSpeechRecognitionAvailability();
    checkTTSAvailability();
  }, []);

  // TTS ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
  const checkTTSAvailability = async () => {
    try {
      // ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ëª©ë¡ í™•ì¸
      const voices = await Speech.getAvailableVoicesAsync();
      console.log('Available voices:', voices.length);
      
      // ì˜ì–´ ìŒì„± ì°¾ê¸°
      const englishVoices = voices.filter(voice => 
        voice.language.startsWith('en') || voice.language.includes('US')
      );
      console.log('English voices found:', englishVoices.length);
      
      if (englishVoices.length > 0) {
        console.log('First English voice:', englishVoices[0]);
      }
      
      // TTS í…ŒìŠ¤íŠ¸ - AI ëª¨ë“œì— ë”°ë¼ ë©”ì‹œì§€ ë³€ê²½
      console.log('Testing TTS...');
      const testMessage = aiMode ? 'AI Interview' : 'Regular Interview';
      await Speech.speak(testMessage, {
        language: 'en-US',
        rate: 0.75,
        onStart: () => console.log('TTS test started'),
        onDone: () => console.log('TTS test completed'),
        onError: (error) => console.error('TTS test error:', error)
      });
      
    } catch (error) {
      console.error('TTS availability check error:', error);
    }
  };

  // STT ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
  const checkSpeechRecognitionAvailability = async () => {
    try {
      // Web Speech API í™•ì¸ (ì›¹ í™˜ê²½ì—ì„œ)
      if (typeof window !== 'undefined' && 'webkitSpeechRecognition' in window) {
        setRecognitionPermission(true);
        setSttEnabled(true);
      } else {
        // ë„¤ì´í‹°ë¸Œ í™˜ê²½ì—ì„œëŠ” ì¼ë‹¨ ë¹„í™œì„±í™”
        setRecognitionPermission(false);
        setSttEnabled(false);
        console.log('Speech recognition not available in this environment');
      }
    } catch (error) {
      console.error('Speech recognition check error:', error);
      setRecognitionPermission(false);
      setSttEnabled(false);
    }
  };

  // OpenAI Whisper STT API í•¨ìˆ˜ (React Native í˜¸í™˜)
  const startSpeechRecognitionWithOpenAI = async () => {
    if (!sttEnabled) {
      Alert.alert('ìŒì„± ì¸ì‹ ë¹„í™œì„±í™”', 'ìŒì„± ì¸ì‹ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.');
      return;
    }

    try {
      setIsRecording(true);
      
      // React Native í™˜ê²½ì—ì„œëŠ” ë°”ë¡œ Web Speech API ì‚¬ìš©
      if (Platform.OS === 'ios' || Platform.OS === 'android') {
        console.log('Using Web Speech API fallback for React Native environment');
        startWebSpeechRecognition();
        return;
      }
      
      // ì›¹ í™˜ê²½ì—ì„œë§Œ MediaRecorder + OpenAI Whisper API ì‹œë„
      if (typeof window !== 'undefined' && typeof navigator !== 'undefined' && navigator.mediaDevices) {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        const mediaRecorder = new MediaRecorder(stream);
        window.currentMediaRecorder = mediaRecorder;
        const audioChunks = [];
        
        mediaRecorder.ondataavailable = (event) => {
          audioChunks.push(event.data);
        };
        
        mediaRecorder.onstop = async () => {
          const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
          
          try {
            const formData = new FormData();
            formData.append('file', audioBlob, 'audio.wav');
            formData.append('model', 'whisper-1');
            formData.append('language', 'en');
            
            const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${OPENAI_API_KEY}`,
              },
              body: formData,
            });

            if (!response.ok) {
              throw new Error(`Whisper API error! status: ${response.status}`);
            }

            const data = await response.json();
            setInputText(data.text);
            
          } catch (error) {
            console.error('OpenAI Whisper Error:', error);
            Alert.alert('ìŒì„± ì¸ì‹ ì˜¤ë¥˜', 'OpenAI ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. Web Speech APIë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤.');
            startWebSpeechRecognition();
          } finally {
            setIsRecording(false);
            stream.getTracks().forEach(track => track.stop());
            window.currentMediaRecorder = null;
          }
        };
        
        mediaRecorder.start();
        setTimeout(() => {
          if (mediaRecorder.state === 'recording') {
            mediaRecorder.stop();
          }
        }, 5000);
      } else {
        throw new Error('MediaRecorder not available');
      }
      
    } catch (error) {
      console.error('Media recording error:', error);
      console.log('Falling back to Web Speech API');
      setIsRecording(false);
      startWebSpeechRecognition();
    }
  };

  // Web Speech API í´ë°± í•¨ìˆ˜
  const startWebSpeechRecognition = async () => {
    try {
      if (typeof window !== 'undefined' && 'webkitSpeechRecognition' in window) {
        const recognition = new window.webkitSpeechRecognition();
        window.currentRecognition = recognition; // ì „ì—­ ì €ì¥ìœ¼ë¡œ ì¤‘ì§€ ê°€ëŠ¥í•˜ê²Œ
        recognition.continuous = false;
        recognition.interimResults = false;
        recognition.lang = 'en-US';
        
        recognition.onresult = async (event) => {
          const transcript = event.results[0][0].transcript;
          setIsRecording(false);
          window.currentRecognition = null;
          setInputText(transcript);
        };
        
        recognition.onerror = (event) => {
          console.error('Speech recognition error:', event.error);
          Alert.alert('ìŒì„± ì¸ì‹ ì˜¤ë¥˜', 'ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
          setIsRecording(false);
          window.currentRecognition = null;
        };
        
        recognition.onend = () => {
          setIsRecording(false);
          window.currentRecognition = null;
        };
        
        recognition.start();
      } else {
        Alert.alert('ìŒì„± ì¸ì‹ ì‚¬ìš© ë¶ˆê°€', 'í˜„ì¬ í™˜ê²½ì—ì„œëŠ” ìŒì„± ì¸ì‹ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
        setIsRecording(false);
      }
    } catch (error) {
      console.error('Web Speech recognition error:', error);
      Alert.alert('ìŒì„± ì¸ì‹ ì˜¤ë¥˜', 'ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      setIsRecording(false);
    }
  };

  // ë©”ì¸ STT í•¨ìˆ˜ (OpenAI ìš°ì„ , Web Speech API í´ë°±)
  const startSpeechRecognition = async () => {
    startSpeechRecognitionWithOpenAI();
  };

  // STT ì¤‘ì§€
  const stopSpeechRecognition = async () => {
    try {
      setIsRecording(false);
      // MediaRecorder ì¤‘ì§€ (OpenAI Whisperìš©)
      if (window.currentMediaRecorder && window.currentMediaRecorder.state === 'recording') {
        window.currentMediaRecorder.stop();
      }
      // Web Speech API ì¤‘ì§€ (í´ë°±ìš©)
      if (window.currentRecognition) {
        window.currentRecognition.stop();
      }
    } catch (error) {
      console.error('Stop speech recognition error:', error);
      setIsRecording(false);
    }
  };



  const testChatGPTConnection = async () => {
    setIsConnecting(true);
    setConnectionStatus('ChatGPT APIì— ì—°ê²° ì¤‘...');
    
    try {
      const testMessages = [
        {
          role: 'user',
          content: 'Hello, can you respond with "API connection successful"?'
        }
      ];
      
      const text = await callChatGPT(testMessages);
      
      if (text) {
        setIsConnected(true);
        setConnectionStatus('');
        console.log('ChatGPT API Response:', text);
      }
    } catch (error) {
      setIsConnected(false);
      setConnectionStatus('âŒ ChatGPT API ì—°ê²° ì‹¤íŒ¨');
      console.error('Connection test failed:', error);
    } finally {
      setIsConnecting(false);
    }
  };

  const startChat = async () => {
    if (!isConnected) {
      Alert.alert('ì—°ê²° ì˜¤ë¥˜', 'ChatGPT APIì— ë¨¼ì € ì—°ê²°í•´ì£¼ì„¸ìš”.');
      return;
    }

    setChatStarted(true);
    setIsLoading(true);
    
    // ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì´ˆê¸° ë©”ì‹œì§€ ì„¤ì •
    const initialMessages = [
      {
        role: 'system',
        content: 'You are a helpful AI assistant for U.S. citizenship interview preparation. You can help with civics questions, interview practice, and general citizenship information. Be professional but friendly. You can conduct mock interviews or answer specific questions about the citizenship process.'
      },
      {
        role: 'user',
        content: 'Hello! I need help preparing for my U.S. citizenship interview. Can you help me?'
      }
    ];

    try {
      let text;
      
      if (aiMode) {
        // GPT ì˜¨ë¼ì¸ ëª¨ë“œ
        console.log('ğŸ¤– Using GPT Online Mode');
        text = await callChatGPT(initialMessages);
        
        // ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        const newHistory = [
          ...initialMessages,
          {
            role: 'assistant',
            content: text
          }
        ];
        setConversationHistory(newHistory);
      } else {
        // ë¡œì»¬ í™˜ê²½ ëª¨ë“œ
        console.log('ğŸ’» Using Local Environment Mode');
        text = await getLocalAIResponse('Hello! I need help preparing for my U.S. citizenship interview. Can you help me?');
        
        // ë¡œì»¬ ëª¨ë“œì—ì„œëŠ” ê°„ë‹¨í•œ ëŒ€í™” ê¸°ë¡ë§Œ ìœ ì§€
        setConversationHistory([
          {
            role: 'user',
            content: 'Hello! I need help preparing for my U.S. citizenship interview. Can you help me?'
          },
          {
            role: 'assistant',
            content: text
          }
        ]);
      }
      
      // ì±„íŒ… ë©”ì‹œì§€ì— ì¶”ê°€ (UIìš©)
      const welcomeMessage = {
        id: Date.now(),
        text: text,
        isUser: false,
        timestamp: new Date()
      };
      
      setMessages([welcomeMessage]);
      
      // OpenAI TTSë¡œ ì‘ë‹µ ì½ê¸°
      console.log('ğŸ“¢ About to call TTS for welcome message');
      console.log('ğŸ“¢ TTS Enabled:', ttsEnabled);
      console.log('ğŸ“¢ Welcome text length:', text.length);
      if (ttsEnabled) {
        console.log('ğŸ“¢ Calling speakTextWithOpenAI for welcome message');
        await speakTextWithOpenAI(text);
      } else {
        console.log('ğŸ“¢ TTS is disabled, skipping welcome message speech');
      }
    } catch (error) {
      Alert.alert('ì˜¤ë¥˜', t('menu.aiChat.errors.cannotStartChat') + ': ' + error.message);
      setChatStarted(false);
    } finally {
      setIsLoading(false);
    }
  };

  const sendMessage = async () => {
    if (!inputText.trim()) {
      return;
    }

    const userMessage = {
      id: Date.now(),
      text: inputText.trim(),
      isUser: true,
      timestamp: new Date()
    };

    // ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì±„íŒ…ì— ì¶”ê°€
    setMessages(prev => [...prev, userMessage]);
    const currentInput = inputText.trim();
    setInputText('');
    setIsLoading(true);

    try {
      let text;
      
      if (aiMode) {
        // GPT ì˜¨ë¼ì¸ ëª¨ë“œ
        console.log('ğŸ¤– Using GPT Online Mode for user message');
        
        // ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ì— ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        const updatedHistory = [
          ...conversationHistory,
          {
            role: 'user',
            content: currentInput
          }
        ];
        
        text = await callChatGPT(updatedHistory);
        
        // ëŒ€í™” ê¸°ë¡ì— AI ì‘ë‹µ ì¶”ê°€
        const finalHistory = [
          ...updatedHistory,
          {
            role: 'assistant',
            content: text
          }
        ];
        setConversationHistory(finalHistory);
      } else {
        // ë¡œì»¬ í™˜ê²½ ëª¨ë“œ
        console.log('ğŸ’» Using Local Environment Mode for user message');
        text = await getLocalAIResponse(currentInput);
        
        // ë¡œì»¬ ëª¨ë“œì—ì„œëŠ” ê°„ë‹¨í•œ ëŒ€í™” ê¸°ë¡ë§Œ ìœ ì§€
        const updatedHistory = [
          ...conversationHistory,
          {
            role: 'user',
            content: currentInput
          },
          {
            role: 'assistant',
            content: text
          }
        ];
        setConversationHistory(updatedHistory);
      }
      
      // AI ì‘ë‹µì„ ì±„íŒ…ì— ì¶”ê°€
      const aiMessage = {
        id: Date.now() + 1,
        text: text,
        isUser: false,
        timestamp: new Date()
      };
      
      setMessages(prev => [...prev, aiMessage]);
      
      // OpenAI TTSë¡œ ì‘ë‹µ ì½ê¸°
      console.log('ğŸ“¢ About to call TTS for user message response');
      console.log('ğŸ“¢ TTS Enabled:', ttsEnabled);
      console.log('ğŸ“¢ Response text length:', text.length);
      if (ttsEnabled) {
        console.log('ğŸ“¢ Calling speakTextWithOpenAI for user message response');
        await speakTextWithOpenAI(text);
      } else {
        console.log('ğŸ“¢ TTS is disabled, skipping user message response speech');
      }
    } catch (error) {
      Alert.alert('ì˜¤ë¥˜', 'AI ì‘ë‹µì„ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ' + error.message);
    } finally {
      setIsLoading(false);
    }
  };

  const scrollToBottom = () => {
    scrollViewRef.current?.scrollToEnd({ animated: true });
  };

  useEffect(() => {
    if (messages.length > 0) {
      setTimeout(scrollToBottom, 100);
    }
  }, [messages]);

  // í™”ë©´ í¬ì»¤ìŠ¤ ê´€ë¦¬ - í™”ë©´ì„ ë²—ì–´ë‚  ë•Œ ëª¨ë“  ìŒì„± ì‘ë™ ì¤‘ì§€ ë° ì´ˆê¸°í™”
  useFocusEffect(
    useCallback(() => {
      console.log('ğŸ”„ AIChatScreen focused - initializing...');
      
      // í™”ë©´ì„ ë²—ì–´ë‚  ë•Œ ì‹¤í–‰ë˜ëŠ” cleanup í•¨ìˆ˜
      return () => {
        console.log('ğŸ”„ AIChatScreen unfocused - cleaning up all audio...');
        
        // 1. ëª¨ë“  TTS ì¤‘ì§€
        if (isSpeaking) {
          console.log('ğŸ”Š Stopping all TTS due to screen navigation...');
          
          // Expo Speech ì¤‘ì§€
          Speech.stop();
          
          // Expo AV ì˜¤ë””ì˜¤ ì¤‘ì§€ (OpenAI TTS ëª¨ë°”ì¼ ì¬ìƒ)
          if (typeof window !== 'undefined' && window.currentExpoSound) {
            console.log('ğŸ”Š Stopping Expo AV sound...');
            window.currentExpoSound.unloadAsync().catch(console.error);
            window.currentExpoSound = null;
          }
          
          setIsSpeaking(false);
        }
        
        // 2. ëª¨ë“  STT ì¤‘ì§€
        if (isRecording) {
          console.log('ğŸ¤ Stopping STT due to screen navigation...');
          if (typeof window !== 'undefined' && window.currentRecognition) {
            window.currentRecognition.stop();
            window.currentRecognition = null;
          }
          if (window.mediaRecorder && window.mediaRecorder.state === 'recording') {
            window.mediaRecorder.stop();
            window.mediaRecorder = null;
          }
          setIsRecording(false);
        }
        
        // 3. ì „ì—­ ì˜¤ë””ì˜¤ ê°ì²´ ì •ë¦¬ (ì›¹ OpenAI TTS)
        if (typeof window !== 'undefined') {
          if (window.currentAudio) {
            console.log('ğŸ”Š Stopping web audio due to screen navigation...');
            window.currentAudio.pause();
            window.currentAudio.currentTime = 0;
            window.currentAudio = null;
          }
        }
        
        // 4. ìŒì„± ìƒ˜í”Œ ì¬ìƒ ì¤‘ì§€
        console.log('ğŸ”Š Stopping voice samples due to screen navigation...');
        stopCurrentSample();
        
        // 4. ë¡œë”© ìƒíƒœ ì´ˆê¸°í™”
        setIsLoading(false);
        
        console.log('âœ… Audio cleanup completed');
      };
    }, [isSpeaking, isRecording])
  );

  const renderMessage = (message) => (
    <View
      key={message.id}
      style={[
        styles.messageContainer,
        message.isUser ? styles.userMessage : styles.aiMessage
      ]}
    >
      <View
        style={[
          styles.messageBubble,
          message.isUser ? styles.userBubble : styles.aiBubble
        ]}
      >
        <Text
          style={[
            styles.messageText,
            message.isUser ? styles.userText : styles.aiText
          ]}
        >
          {message.text}
        </Text>
        <Text style={styles.timestamp}>
          {message.timestamp.toLocaleTimeString([], { 
            hour: '2-digit', 
            minute: '2-digit' 
          })}
        </Text>
      </View>
    </View>
  );

  return (
    <SafeAreaView style={styles.container}>
      <StatusBar barStyle="dark-content" backgroundColor="#f8f9fa" />
      
      {/* í—¤ë” */}
      <View style={styles.header}>
        <TouchableOpacity
          style={styles.backButton}
          onPress={() => navigation.goBack()}
        >
          <Ionicons name="arrow-back" size={24} color="#333" />
        </TouchableOpacity>
        
        <Text style={styles.headerTitle}>{t('menu.aiChat.title')}</Text>
        
        <View style={styles.headerButtons}>
          {/* AI ëª¨ë“œ í† ê¸€ */}
          <View style={styles.aiModeContainer}>
            <Text style={styles.aiModeLabel}>AI</Text>
            <TouchableOpacity
              style={[
                styles.aiModeToggle,
                aiMode ? styles.aiModeToggleOn : styles.aiModeToggleOff
              ]}
              onPress={() => {
                const newMode = !aiMode;
                setAiMode(newMode);
                announceAiModeChange(newMode);
              }}
            >
              <View style={[
                styles.aiModeIndicator,
                aiMode ? styles.aiModeIndicatorOn : styles.aiModeIndicatorOff
              ]} />
            </TouchableOpacity>
          </View>
          
          <View style={styles.headerButton}>
            <Ionicons 
              name="mic" 
              size={20} 
              color="#007AFF" 
            />
          </View>
          
          <View style={styles.headerButton}>
            <Ionicons 
              name="volume-high" 
              size={20} 
              color="#007AFF" 
            />
          </View>
          

        </View>
      </View>

      {/* ë©”ì¸ ì»¨í…ì¸  ì˜ì—­ - ë¹„ìœ¨ ê¸°ë°˜ ë ˆì´ì•„ì›ƒ */}
      {!chatStarted && (
        <View style={styles.mainContentContainer}>
          {/* ì—°ê²° ìƒíƒœ */}
          <View style={styles.connectionStatusContainer}>
            <Text style={styles.statusText}>{connectionStatus}</Text>
            {isConnecting && <ActivityIndicator size="small" color="#007AFF" />}
          </View>
          
          {/* Instructions ì˜ì—­ - ìƒë‹¨ 3/5 */}
          <View style={styles.instructionSection}>
            <View style={styles.instructionContainer}>
              <View style={styles.instructionHeader}>
                <Ionicons name="information-circle" size={20} color="#666" />
                <Text style={styles.instructionTitle}>{t('menu.aiChat.instructions.title')}</Text>
              </View>
              
              <ScrollView 
                style={styles.instructionScrollView}
                contentContainerStyle={styles.instructionScrollContent}
                showsVerticalScrollIndicator={false}
              >
                <View style={styles.instructionContent}>
                  {/* AI Interview ëª¨ë“œ ì„¤ëª… */}
                  <View style={styles.modeSection}>
                    <Text style={styles.modeSectionTitle}>{t('menu.aiChat.instructions.aiModeTitle')}</Text>
                    <View style={styles.instructionItem}>
                      <Text style={styles.instructionBullet}>â€¢</Text>
                      <Text style={styles.instructionText}>{t('menu.aiChat.instructions.aiModeDesc1')}</Text>
                    </View>
                    <View style={styles.instructionItem}>
                      <Text style={styles.instructionBullet}>â€¢</Text>
                      <Text style={styles.instructionText}>{t('menu.aiChat.instructions.aiModeDesc2')}</Text>
                    </View>
                    <View style={styles.instructionItem}>
                      <Text style={styles.instructionBullet}>â€¢</Text>
                      <Text style={styles.instructionText}>{t('menu.aiChat.instructions.aiModeDesc3')}</Text>
                    </View>
                  </View>

                  {/* Regular Interview ëª¨ë“œ ì„¤ëª… */}
                  <View style={styles.modeSection}>
                    <Text style={styles.modeSectionTitle}>{t('menu.aiChat.instructions.regularModeTitle')}</Text>
                    <View style={styles.instructionItem}>
                      <Text style={styles.instructionBullet}>â€¢</Text>
                      <Text style={styles.instructionText}>{t('menu.aiChat.instructions.regularModeDesc1')}</Text>
                    </View>
                    <View style={styles.instructionItem}>
                      <Text style={styles.instructionBullet}>â€¢</Text>
                      <Text style={styles.instructionText}>{t('menu.aiChat.instructions.regularModeDesc2')}</Text>
                    </View>
                    <View style={styles.instructionItem}>
                      <Text style={styles.instructionBullet}>â€¢</Text>
                      <Text style={styles.instructionText}>{t('menu.aiChat.instructions.regularModeDesc3')}</Text>
                    </View>
                  </View>

                  {/* ê³µí†µ ì‚¬ìš©ë²• */}
                  <View style={styles.modeSection}>
                    <Text style={styles.modeSectionTitle}>{t('menu.aiChat.instructions.howToUseTitle')}</Text>
                    <View style={styles.instructionItem}>
                      <Text style={styles.instructionBullet}>â€¢</Text>
                      <Text style={styles.instructionText}>{t('menu.aiChat.instructions.howToUseDesc1')}</Text>
                    </View>
                    <View style={styles.instructionItem}>
                      <Text style={styles.instructionBullet}>â€¢</Text>
                      <Text style={styles.instructionText}>{t('menu.aiChat.instructions.howToUseDesc2')}</Text>
                    </View>
                    <View style={styles.instructionItem}>
                      <Text style={styles.instructionBullet}>â€¢</Text>
                      <Text style={styles.instructionText}>{t('menu.aiChat.instructions.howToUseDesc3')}</Text>
                    </View>
                  </View>
                </View>
              </ScrollView>
            </View>
          </View>

          {/* Voice Selection ì˜ì—­ - ê³ ì • ë†’ì´ */}
          <View style={styles.voiceSection}>
            <View style={styles.voiceSelectionContainer}>
              <View style={styles.voiceSelectionHeader}>
                <Ionicons name="mic" size={20} color="#666" />
                <Text style={styles.voiceSelectionTitle}>{t('menu.aiChat.voiceSelection.title')}</Text>
              </View>
              
              <ScrollView 
                horizontal 
                style={styles.voiceOptionsScrollView}
                contentContainerStyle={styles.voiceOptionsContainer}
                showsHorizontalScrollIndicator={false}
              >
                {openaiVoices.map((voice) => (
                  <TouchableOpacity
                    key={voice.id}
                    style={[
                      styles.voiceCard,
                      styles.voiceOption,
                      selectedVoice === voice.id && styles.voiceOptionSelected
                    ]}
                    onPress={() => {
                      setSelectedVoice(voice.id);
                      playVoiceSample(voice.id); // ìë™ ìƒ˜í”Œ ì¬ìƒ
                    }}
                  >
                    <View style={styles.voiceInfo}>
                      <Text style={[
                        styles.voiceName,
                        selectedVoice === voice.id && styles.voiceNameSelected
                      ]}>
                        {voice.name}
                      </Text>
                      <Text style={[
                        styles.voiceDescription,
                        selectedVoice === voice.id && styles.voiceDescriptionSelected
                      ]}>
                        {t(`menu.aiChat.voiceSelection.voices.${voice.descriptionKey}`)}
                      </Text>
                    </View>
                  </TouchableOpacity>
                ))}
              </ScrollView>
            </View>
          </View>
        </View>
      )}

      {/* ë²„íŠ¼ ì˜ì—­ - í•­ìƒ í‘œì‹œ */}
      <View style={styles.buttonSection}>
        <TouchableOpacity
          style={styles.startButton}
          onPress={aiMode ? () => {
            // ìŒì„± ìƒ˜í”Œ ì¬ìƒ ì¤‘ì§€
            stopCurrentSample();
            // ì„ íƒëœ ìŒì„±ê³¼ í•¨ê»˜ AI Interviewë¡œ ì´ë™
            navigation.navigate('AIInterview', { selectedVoice: selectedVoice });
          } : startChat}
          disabled={isLoading || chatStarted || (aiMode && !isConnected)}
        >
          <Text style={styles.startButtonText}>
            {aiMode ? t('menu.aiChat.buttons.startAiInterview') : t('menu.aiChat.buttons.startLocalChat')}
          </Text>
        </TouchableOpacity>
      </View>



      {/* ì±„íŒ… ì˜ì—­ */}
      {chatStarted && (
        <KeyboardAvoidingView 
          style={styles.chatContainer}
          behavior={Platform.OS === 'ios' ? 'padding' : 'height'}
        >
          <ScrollView
            ref={scrollViewRef}
            style={styles.messagesContainer}
            showsVerticalScrollIndicator={false}
          >
            {messages.map(renderMessage)}
            {isLoading && (
              <View style={styles.loadingContainer}>
                <ActivityIndicator size="small" color="#007AFF" />
                <Text style={styles.loadingText}>ChatGPTê°€ ì‘ë‹µí•˜ëŠ” ì¤‘...</Text>
                <Text style={styles.loadingSubtext}>GPT-3.5-turbo ëª¨ë¸ ì‚¬ìš©</Text>
              </View>
            )}
          </ScrollView>

          {/* ì…ë ¥ ì˜ì—­ */}
          <View style={styles.inputContainer}>
            <TextInput
              style={styles.textInput}
              value={inputText}
              onChangeText={setInputText}
              placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ìŒì„± ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”..."
              multiline
              maxLength={500}
              editable={!isLoading && !isRecording}
            />
            
            {/* ìŒì„± ì…ë ¥ ë²„íŠ¼ */}
            {sttEnabled && recognitionPermission && (
              <TouchableOpacity
                style={[
                  styles.micButton,
                  isRecording && styles.micButtonRecording
                ]}
                onPress={isRecording ? stopSpeechRecognition : startSpeechRecognition}
                disabled={isLoading}
              >
                <Ionicons 
                  name={isRecording ? "stop" : "mic"} 
                  size={20} 
                  color={isRecording ? "#FF3B30" : "#007AFF"} 
                />
              </TouchableOpacity>
            )}
            
            <TouchableOpacity
              style={[
                styles.sendButton,
                (!inputText.trim() || isLoading) && styles.sendButtonDisabled
              ]}
              onPress={sendMessage}
              disabled={!inputText.trim() || isLoading}
            >
              <Ionicons 
                name="send" 
                size={20} 
                color={(!inputText.trim() || isLoading) ? "#999" : "#007AFF"} 
              />
            </TouchableOpacity>
          </View>
        </KeyboardAvoidingView>
      )}

      {/* TTS ìƒíƒœ í‘œì‹œ */}
      {isSpeaking && (
        <View style={styles.speakingIndicator}>
          <Ionicons name="volume-high" size={16} color="#007AFF" />
          <Text style={styles.speakingText}>
            {Platform.OS === 'web' ? 'OpenAI TTSë¡œ ìŒì„± ì¬ìƒ ì¤‘...' : 'Expo Speechë¡œ ìŒì„± ì¬ìƒ ì¤‘...'}
          </Text>
          <TouchableOpacity onPress={stopSpeaking}>
            <Text style={styles.stopText}>ì¤‘ì§€</Text>
          </TouchableOpacity>
        </View>
      )}

      {/* STT ìƒíƒœ í‘œì‹œ */}
      {isRecording && (
        <View style={styles.recordingIndicator}>
          <View style={styles.recordingDot} />
          <Text style={styles.recordingText}>
            {Platform.OS === 'web' ? 'OpenAI Whisperë¡œ ìŒì„± ì¸ì‹ ì¤‘...' : 'Web Speech APIë¡œ ìŒì„± ì¸ì‹ ì¤‘...'}
          </Text>
          <TouchableOpacity onPress={stopSpeechRecognition}>
            <Text style={styles.stopText}>ì¤‘ì§€</Text>
          </TouchableOpacity>
        </View>
      )}

      {/* ìŒì„± ì„ íƒ ëª¨ë‹¬ */}
      <Modal
        visible={showVoiceSelector}
        transparent={true}
        animationType="slide"
        onRequestClose={() => setShowVoiceSelector(false)}
      >
        <View style={styles.modalOverlay}>
          <View style={styles.voiceSelectorModal}>
            <View style={styles.modalHeader}>
              <Text style={styles.modalTitle}>ğŸ¤ OpenAI ìŒì„± ì„ íƒ</Text>
              <TouchableOpacity
                onPress={() => setShowVoiceSelector(false)}
                style={styles.modalCloseButton}
              >
                <Ionicons name="close" size={24} color="#333" />
              </TouchableOpacity>
            </View>
            
            <Text style={styles.modalSubtitle}>
              chat.openai.comê³¼ ë™ì¼í•œ ê³ í’ˆì§ˆ AI ìŒì„±ì„ ì„ íƒí•˜ì„¸ìš”
            </Text>
            
            <ScrollView style={styles.voiceList}>
              {openaiVoices.map((voice) => (
                <TouchableOpacity
                  key={voice.id}
                  style={[
                    styles.voiceOption,
                    selectedVoice === voice.id && styles.voiceOptionSelected
                  ]}
                  onPress={() => {
                    setSelectedVoice(voice.id);
                    setShowVoiceSelector(false);
                  }}
                >
                  <View style={styles.voiceInfo}>
                    <Text style={[
                      styles.voiceName,
                      selectedVoice === voice.id && styles.voiceNameSelected
                    ]}>
                      {voice.name}
                    </Text>
                    <Text style={[
                      styles.voiceDescription,
                      selectedVoice === voice.id && styles.voiceDescriptionSelected
                    ]}>
                      {voice.description}
                    </Text>
                  </View>
                  {selectedVoice === voice.id && (
                    <Ionicons name="checkmark-circle" size={24} color="#007AFF" />
                  )}
                </TouchableOpacity>
              ))}
            </ScrollView>
            
            <View style={styles.modalFooter}>
              <Text style={styles.modalNote}>
                ğŸ’¡ ìŒì„± ë³€ê²½ì€ ë‹¤ìŒ ë©”ì‹œì§€ë¶€í„° ì ìš©ë©ë‹ˆë‹¤
              </Text>
            </View>
          </View>
        </View>
      </Modal>
    </SafeAreaView>
  );
};

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: '#f8f9fa',
  },
  header: {
    flexDirection: 'row',
    alignItems: 'center',
    justifyContent: 'space-between',
    paddingHorizontal: 20,
    paddingVertical: 15,
    backgroundColor: '#fff',
    borderBottomWidth: 1,
    borderBottomColor: '#e9ecef',
  },
  backButton: {
    padding: 5,
  },
  headerTitle: {
    fontSize: 18,
    fontWeight: 'bold',
    color: '#333',
  },
  headerButtons: {
    flexDirection: 'row',
    alignItems: 'center',
    gap: 10,
  },
  headerButton: {
    padding: 5,
  },
  aiModeContainer: {
    flexDirection: 'row',
    alignItems: 'center',
    gap: 8,
  },
  aiModeLabel: {
    fontSize: 12,
    fontWeight: 'bold',
    color: '#333',
  },
  aiModeToggle: {
    width: 40,
    height: 20,
    borderRadius: 10,
    justifyContent: 'center',
    paddingHorizontal: 2,
  },
  aiModeToggleOn: {
    backgroundColor: '#34C759', // ì´ˆë¡ìƒ‰ - GPT ì˜¨ë¼ì¸ ëª¨ë“œ
  },
  aiModeToggleOff: {
    backgroundColor: '#8E8E93', // íšŒìƒ‰ - ë¡œì»¬ í™˜ê²½ ëª¨ë“œ
  },
  aiModeIndicator: {
    width: 16,
    height: 16,
    borderRadius: 8,
    backgroundColor: '#fff',
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 1 },
    shadowOpacity: 0.3,
    shadowRadius: 1,
    elevation: 2,
  },
  aiModeIndicatorOn: {
    alignSelf: 'flex-end', // ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì´ë™
  },
  aiModeIndicatorOff: {
    alignSelf: 'flex-start', // ì™¼ìª½ìœ¼ë¡œ ì´ë™
  },
  statusScrollContainer: {
    flex: 1,
    maxHeight: 400, // ìµœëŒ€ ë†’ì´ ì œí•œìœ¼ë¡œ ìŠ¤í¬ë¡¤ ê°€ëŠ¥í•˜ê²Œ
  },
  statusContainer: {
    alignItems: 'center',
    justifyContent: 'center',
    paddingVertical: 15,
    paddingHorizontal: 20,
    minHeight: 100,
  },
  statusText: {
    fontSize: 14,
    color: '#666',
  },
  techStackContainer: {
    marginTop: 15,
    padding: 12,
    backgroundColor: '#f0f8ff',
    borderRadius: 8,
    borderWidth: 1,
    borderColor: '#e0e0e0',
    width: '90%',
    maxWidth: 350,
  },
  techStackTitle: {
    fontSize: 14,
    fontWeight: 'bold',
    color: '#333',
    marginBottom: 8,
    textAlign: 'center',
  },
  techItem: {
    flexDirection: 'row',
    alignItems: 'center',
    marginBottom: 3,
    flexWrap: 'wrap',
  },
  techLabel: {
    fontSize: 12,
    fontWeight: '600',
    color: '#333',
    marginRight: 5,
  },
  techValue: {
    fontSize: 12,
    color: '#666',
    flex: 1,
    flexWrap: 'wrap',
  },
  onlineStatus: {
    color: '#34C759', // ì´ˆë¡ìƒ‰ - ì˜¨ë¼ì¸
    fontWeight: 'bold',
  },
  offlineStatus: {
    color: '#FF9500', // ì£¼í™©ìƒ‰ - ì˜¤í”„ë¼ì¸
    fontWeight: 'bold',
  },
  startContainer: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
    paddingHorizontal: 20,
  },
  startButton: {
    backgroundColor: '#007AFF',
    paddingHorizontal: 40, // ì¢Œìš° íŒ¨ë”© ì¦ê°€
    paddingVertical: 12, // ìƒí•˜ íŒ¨ë”© ê°ì†Œ
    borderRadius: 25,
    alignSelf: 'center', // ì¤‘ì•™ ì •ë ¬
    minWidth: 200, // ìµœì†Œ ë„ˆë¹„ ì„¤ì •
    maxWidth: 280, // ìµœëŒ€ ë„ˆë¹„ ì œí•œ
  },
  startButtonText: {
    color: '#fff',
    fontSize: 16,
    fontWeight: 'bold',
  },

  chatContainer: {
    flex: 1,
  },
  messagesContainer: {
    flex: 1,
    paddingHorizontal: 15,
    paddingVertical: 10,
  },
  messageContainer: {
    marginVertical: 5,
  },
  userMessage: {
    alignItems: 'flex-end',
  },
  aiMessage: {
    alignItems: 'flex-start',
  },
  messageBubble: {
    maxWidth: '80%',
    paddingHorizontal: 15,
    paddingVertical: 10,
    borderRadius: 18,
  },
  userBubble: {
    backgroundColor: '#007AFF',
  },
  aiBubble: {
    backgroundColor: '#fff',
    borderWidth: 1,
    borderColor: '#e9ecef',
  },
  messageText: {
    fontSize: 16,
    lineHeight: 20,
  },
  userText: {
    color: '#fff',
  },
  aiText: {
    color: '#333',
  },
  timestamp: {
    fontSize: 12,
    color: '#999',
    marginTop: 5,
    textAlign: 'right',
  },
  loadingContainer: {
    flexDirection: 'row',
    alignItems: 'center',
    justifyContent: 'center',
    paddingVertical: 15,
    gap: 10,
  },
  loadingText: {
    fontSize: 14,
    color: '#666',
  },
  loadingSubtext: {
    fontSize: 12,
    color: '#999',
    marginTop: 2,
  },
  inputContainer: {
    flexDirection: 'row',
    alignItems: 'flex-end',
    paddingHorizontal: 15,
    paddingVertical: 10,
    backgroundColor: '#fff',
    borderTopWidth: 1,
    borderTopColor: '#e9ecef',
  },
  textInput: {
    flex: 1,
    borderWidth: 1,
    borderColor: '#e9ecef',
    borderRadius: 20,
    paddingHorizontal: 15,
    paddingVertical: 10,
    maxHeight: 100,
    fontSize: 16,
    backgroundColor: '#f8f9fa',
  },
  sendButton: {
    marginLeft: 10,
    padding: 10,
    borderRadius: 20,
    backgroundColor: '#f8f9fa',
  },
  sendButtonDisabled: {
    opacity: 0.5,
  },
  micButton: {
    marginLeft: 10,
    padding: 10,
    borderRadius: 20,
    backgroundColor: '#f8f9fa',
    borderWidth: 1,
    borderColor: '#007AFF',
  },
  micButtonRecording: {
    backgroundColor: '#FFE5E5',
    borderColor: '#FF3B30',
  },
  speakingIndicator: {
    flexDirection: 'row',
    alignItems: 'center',
    justifyContent: 'center',
    paddingVertical: 10,
    backgroundColor: '#e3f2fd',
    gap: 10,
  },
  speakingText: {
    fontSize: 14,
    color: '#007AFF',
  },
  recordingIndicator: {
    flexDirection: 'row',
    alignItems: 'center',
    justifyContent: 'center',
    paddingVertical: 10,
    backgroundColor: '#FFE5E5',
    gap: 10,
  },
  recordingDot: {
    width: 8,
    height: 8,
    borderRadius: 4,
    backgroundColor: '#FF3B30',
  },
  recordingText: {
    fontSize: 14,
    color: '#FF3B30',
  },
  stopText: {
    fontSize: 14,
    color: '#007AFF',
    fontWeight: 'bold',
  },
  modalOverlay: {
    flex: 1,
    backgroundColor: 'rgba(0, 0, 0, 0.5)',
    justifyContent: 'center',
    alignItems: 'center',
  },
  voiceSelectorModal: {
    backgroundColor: '#fff',
    borderRadius: 20,
    margin: 20,
    maxHeight: '80%',
    width: '90%',
    maxWidth: 400,
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 2 },
    shadowOpacity: 0.25,
    shadowRadius: 4,
    elevation: 5,
  },
  modalHeader: {
    flexDirection: 'row',
    justifyContent: 'space-between',
    alignItems: 'center',
    padding: 20,
    borderBottomWidth: 1,
    borderBottomColor: '#e9ecef',
  },
  modalTitle: {
    fontSize: 18,
    fontWeight: 'bold',
    color: '#333',
  },
  modalCloseButton: {
    padding: 5,
  },
  modalSubtitle: {
    fontSize: 14,
    color: '#666',
    textAlign: 'center',
    paddingHorizontal: 20,
    paddingVertical: 10,
  },
  voiceList: {
    maxHeight: 300,
  },
  voiceOption: {
    flex: 1, // ë¶€ëª¨ ì»¨í…Œì´ë„ˆì˜ í¬ê¸°ì— ë§ì¶¤
    padding: 12,
    backgroundColor: '#f8f9fa',
    borderRadius: 12,
    borderWidth: 2,
    borderColor: '#e9ecef',
    justifyContent: 'center', // ì„¸ë¡œ ê°€ìš´ë° ì •ë ¬
    alignItems: 'center', // ê°€ë¡œ ê°€ìš´ë° ì •ë ¬
  },
  voiceOptionSelected: {
    backgroundColor: '#e3f2fd',
    borderColor: '#007AFF',
    shadowColor: '#007AFF',
    shadowOffset: { width: 0, height: 2 },
    shadowOpacity: 0.2,
    shadowRadius: 4,
    elevation: 4,
  },
  voiceInfo: {
    flex: 1,
  },
  voiceName: {
    fontSize: 15, // í¬ê¸° ì¦ê°€
    fontWeight: 'bold',
    color: '#333',
    textAlign: 'center', // ê°€ìš´ë° ì •ë ¬
    marginBottom: 4,
  },
  voiceNameSelected: {
    color: '#007AFF',
  },
  voiceDescription: {
    fontSize: 12,
    color: '#666',
    textAlign: 'center', // ê°€ìš´ë° ì •ë ¬
    lineHeight: 16,
  },
  voiceDescriptionSelected: {
    color: '#0056b3',
  },
  modalFooter: {
    padding: 15,
    borderTopWidth: 1,
    borderTopColor: '#e9ecef',
  },
  modalNote: {
    fontSize: 12,
    color: '#666',
    textAlign: 'center',
    fontStyle: 'italic',
  },
  
  // ë©”ì¸ ì»¨í…ì¸  ì»¨í…Œì´ë„ˆ - ê³ ì • í•˜ë‹¨ ë²„íŠ¼ ë ˆì´ì•„ì›ƒ
  mainContentContainer: {
    flex: 1,
    flexDirection: 'column',
  },
  voiceOptionsContainer: {
    paddingHorizontal: 20, // ì¢Œìš° íŒ¨ë”© ì¦ê°€
    paddingVertical: 10,
    gap: 12, // ê°„ê²© ì¦ê°€
  },
  connectionStatusContainer: {
    paddingHorizontal: 15,
    paddingVertical: 10,
    alignItems: 'center',
  },
  
  // Instructions ì˜ì—­ - ë‚˜ë¨¸ì§€ ê³µê°„ ëª¨ë‘ ì‚¬ìš©
  instructionSection: {
    flex: 1, // ë‚˜ë¨¸ì§€ ê³µê°„ ëª¨ë‘ ì‚¬ìš©
    paddingHorizontal: 0, // Full width
  },
  instructionContainer: {
    backgroundColor: '#fff',
    borderRadius: 0, // Full width
    marginHorizontal: 0, // Full width
    marginVertical: 5,
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 2 },
    shadowOpacity: 0.1,
    shadowRadius: 4,
    elevation: 3,
    borderWidth: 1,
    borderColor: '#e9ecef',
    flex: 1,
  },
  instructionHeader: {
    flexDirection: 'row',
    alignItems: 'center',
    paddingHorizontal: 15,
    paddingTop: 15,
    paddingBottom: 10,
    gap: 8,
    borderBottomWidth: 1,
    borderBottomColor: '#f0f0f0',
  },
  instructionTitle: {
    fontSize: 16,
    fontWeight: 'bold',
    color: '#333',
  },
  instructionScrollView: {
    flex: 1,
  },
  instructionScrollContent: {
    padding: 15,
  },
  instructionContent: {
    gap: 8,
  },
  instructionItem: {
    flexDirection: 'row',
    alignItems: 'flex-start',
    gap: 8,
  },
  instructionBullet: {
    fontSize: 14,
    color: '#666',
    marginTop: 2,
  },
  instructionText: {
    fontSize: 14,
    color: '#555',
    flex: 1,
    lineHeight: 20,
  },
  
  // ëª¨ë“œ ì„¹ì…˜ ìŠ¤íƒ€ì¼
  modeSection: {
    marginBottom: 20,
  },
  modeSectionTitle: {
    fontSize: 16,
    fontWeight: 'bold',
    color: '#333',
    marginBottom: 8,
    paddingBottom: 4,
    borderBottomWidth: 1,
    borderBottomColor: '#e9ecef',
  },
  
  // ë²„íŠ¼ ì˜ì—­ - í•˜ë‹¨ ê³ ì •
  buttonSection: {
    height: 130, // ë†’ì´ ì¦ê°€ (100 â†’ 130)
    justifyContent: 'center',
    paddingHorizontal: 20,
    paddingVertical: 20, // ìƒí•˜ íŒ¨ë”© ì¶”ê°€
    backgroundColor: '#f8f9fa',
    borderTopWidth: 1,
    borderTopColor: '#e9ecef',
  },
  
  // Voice Selection ì˜ì—­ - ê³ ì • ë†’ì´
  voiceSection: {
    height: 160, // ë†’ì´ ì¦ê°€ (120 â†’ 160)
    paddingHorizontal: 0, // Full width
  },
  voiceSelectionContainer: {
    backgroundColor: '#fff',
    borderRadius: 0, // Full width
    marginHorizontal: 0, // Full width
    marginVertical: 5,
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 2 },
    shadowOpacity: 0.1,
    shadowRadius: 4,
    elevation: 3,
    borderWidth: 1,
    borderColor: '#e9ecef',
    flex: 1,
  },
  voiceSelectionHeader: {
    flexDirection: 'row',
    alignItems: 'center',
    paddingHorizontal: 15,
    paddingTop: 15,
    paddingBottom: 10,
    gap: 8,
    borderBottomWidth: 1,
    borderBottomColor: '#f0f0f0',
  },
  voiceSelectionTitle: {
    fontSize: 16,
    fontWeight: 'bold',
    color: '#333',
  },
  voiceOptions: {
    gap: 10,
  },
  voiceOptionLeft: {
    flexDirection: 'row',
    alignItems: 'center',
    flex: 1,
    gap: 12,
  },
  // Radial ë²„íŠ¼ ë° Sample ë²„íŠ¼ ì œê±° - ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
  voiceInfo: {
    alignItems: 'center', // ê°€ìš´ë° ì •ë ¬
    justifyContent: 'center',
  },
});

export default AIChatScreen;
